# Libraries
import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
import warnings
warnings.filterwarnings('ignore')
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler as SS
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from yellowbrick.cluster import SilhouetteVisualizer
import scipy.cluster.hierarchy as hcluster
from sklearn.cluster import AgglomerativeClustering
from sklearn.cluster import DBSCAN
from sklearn.neighbors import NearestNeighbors
from matplotlib import pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

import plotly.express as px
!pip install -U kaleido
import kaleido
# Data analysis
df=pd.read_csv('/content/Country-data.csv')
df
df.info()
sns.heatmap(df.isnull(),cmap = 'viridis')
we can see above that we dont have any null values is the dataset
df.shape
finding duplicate values
format(len(df[df.duplicated()]))
df.describe()
Findings:


*   small dataset
*   no missing values
*   no duplicate values 
*   some outliers and skewed distribution

df
# Data Visualization
plt.figure(figsize=(12,5))
plt.title("Child Mortality: Death of children under 5 years of age per 1000 live births")
ax = sns.histplot(df["child_mort"])
plt.figure(figsize=(12,5))
plt.title("Exports: Exports of goods and services per capita. Given as %age of the GDP per capita")
ax = sns.histplot(df["exports"])
plt.figure(figsize=(12,5))
plt.title("Imports: Imports of goods and services per capita. Given as %age of the GDP per capita")
ax = sns.histplot(df["imports"])
plt.figure(figsize=(12,5))
plt.title("Health: Total health spending per capita. Given as %age of GDP per capita")
ax = sns.histplot(df["health"])
plt.figure(figsize=(12,5))
plt.title("Income: Net income per person")
ax = sns.histplot(df["income"])
plt.figure(figsize=(12,5))
plt.title("Inflation: The measurement of the annual growth rate of the Total GDP")
ax = sns.histplot(df["inflation"])
plt.figure(figsize=(12,5))
plt.title("Life expectancy: The average number of years a new born child would live if the current mortality patterns are to remain the same")
ax = sns.histplot(df["life_expec"])
plt.figure(figsize=(12,5))
plt.title("New Population :The number of children that would be born to each woman if the current age-fertility rates remain the same.")
ax = sns.histplot(df["total_fer"])
plt.figure(figsize=(12,5))
plt.title("GDP: The GDP per capita. Calculated as the Total GDP divided by the total population.")
ax = sns.histplot(df["gdpp"])
plt.figure(figsize=(15,10))
sns.heatmap(df.corr(method='pearson', min_periods=1),annot=True)
**We can see that there are a few features that might be considered for elimination due to high correlation:**

life_expect, due to high correlation with child mortality

total_fertility, due to high correlation with child mortality


# Scaling
data_n=df.drop(['country'], axis =1)
columns=data_n.columns
scale=SS()
rescaled_dataset = scale.fit_transform(data_n)
rescaled_dataset
df_standard = pd.DataFrame(data= rescaled_dataset, columns = columns)
df_standard
# PCA
from sklearn.decomposition import PCA
pca = PCA()
pca.fit(df_standard)
pca_data_standard = pca.transform(df_standard)
pca_data_standard
var=pca.explained_variance_ratio_*100
var
plt.bar(x=range(1,10), height=var)
plt.ylabel('Percentage of Explained Variance')
plt.xlabel('Principal Component')
plt.title('Scree Plot')
plt.show()
labels = ['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9']
pca_df_standard = pd.DataFrame(pca_data_standard, columns = labels)
plt.scatter(pca_df_standard.PC1, pca_df_standard.PC2)
plt.title('PCA')
plt.xlabel('PC1 - {0}%'.format(var[0]))
plt.ylabel('PC2 - {0}%'.format(var[1]))
data_pca= pca_df_standard.drop(['PC6','PC7','PC8','PC9'], axis = 1)
data_pca

# K means on normal datset
To Apply K-means we first have to decide how many clusters are optimum
df1=df.copy()
df1
sse = []
for i in range(1, 11):
    km = KMeans( n_clusters=i )
    km.fit(df_standard)
    sse.append(km.inertia_)
# plot
plt.plot(range(1, 11), sse, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('SSE')
plt.show()


from sklearn.metrics import silhouette_score
score=[]
n=range(2,15)
for i in n:
      km = KMeans(n_clusters=i)
      km = km.fit(df_standard)
      cluster_labels=km.labels_
      score.append(silhouette_score(df_standard, cluster_labels))
k=score.index(max(score))
print("best n:" ,k)
print("best silhouette_score:",score[k-1])
plt.plot(score)
plt.xlabel('Values of n') 
plt.ylabel('Silhouette score') 
plt.title('Silhouette analysis For Optimal k')
plt.show()
**We kan see that the optimum number of cluster is 3**


kmeans = KMeans(n_clusters = 3)
kmeans.fit(df_standard)
kmeans.labels_
pd.Series(kmeans.labels_).value_counts()
kmeans_df = pd.DataFrame(df1)
kmeans_df['KMeans_Clusters'] = kmeans.labels_
kmeans_df.head(10)
features=list(data_n.columns)
features
kmeans_df_n=kmeans_df.drop(['country'], axis =1)
kmeans_df_n
for i in range(9):
  for  j in range(i+1,9):
    labels = kmeans.labels_
    sns.scatterplot(x=kmeans_df_n.iloc[:, i], y=kmeans_df_n.iloc[:, j], hue='KMeans_Clusters', data=kmeans_df_n)
    plt.title(kmeans_df_n.columns[i]+" vs "+kmeans_df_n.columns[j], fontsize=15)
    plt.xlabel(kmeans_df_n.columns[i], fontsize=12)
    plt.ylabel(kmeans_df_n.columns[j], fontsize=12)
    plt.show()
    
fig,ax = plt.subplots(2,3, figsize=(20,10),squeeze=False)
sns.barplot(x='KMeans_Clusters', y=kmeans_df_n.columns[0],data=kmeans_df_n,ax=ax[0,0])
sns.barplot(x='KMeans_Clusters', y=kmeans_df_n.columns[1],data=kmeans_df_n,ax=ax[0,1])
sns.barplot(x='KMeans_Clusters', y=kmeans_df_n.columns[2],data=kmeans_df_n,ax=ax[0,2])
sns.barplot(x='KMeans_Clusters', y=kmeans_df_n.columns[4],data=kmeans_df_n,ax=ax[1,0])
sns.barplot(x='KMeans_Clusters', y=kmeans_df_n.columns[6],data=kmeans_df_n,ax=ax[1,1])
sns.barplot(x='KMeans_Clusters', y=kmeans_df_n.columns[8],data=kmeans_df_n,ax=ax[1,2])

plt.show()
under_developing=kmeans_df[kmeans_df['KMeans_Clusters']==2]['country']
developing=kmeans_df[kmeans_df['KMeans_Clusters']==1]['country']
developed=kmeans_df[kmeans_df['KMeans_Clusters']==0]['country']
kmeans_df
**Under developed country according to k-means**
under_developing
**Developing country according to k-means**
print(developing)
**Developed country according to k-means**
developed
kmeans_df_copy=kmeans_df.copy()
kmeans_df_copy
kmeans_df_copy['KMeans_Clusters'].loc[kmeans_df_copy['KMeans_Clusters'] == 2] = 'Help Needed'
kmeans_df_copy['KMeans_Clusters'].loc[kmeans_df_copy['KMeans_Clusters'] == 1] = 'Might need help'
kmeans_df_copy['KMeans_Clusters'].loc[kmeans_df_copy['KMeans_Clusters'] == 0] = 'No need'
fig = px.choropleth(kmeans_df_copy[['country','KMeans_Clusters']],
                    locationmode = 'country names',
                    locations = 'country',
                    title = 'Needed Help Per Country (World)',
                    color = kmeans_df_copy['KMeans_Clusters'],  
                    color_discrete_map = {'Help Needed':'Red',
                                        'No Help Needed':'Green',
                                        'Might Need Help':'Yellow'}
                   )
fig.update_geos(fitbounds = "locations", visible = True)
fig.update_layout(legend_title_text = 'Labels',legend_title_side = 'top',title_pad_l = 260,title_y = 0.86)
fig.show(engine = 'kaleido')
# Kmeans on PCA dataset
df_=df.copy()
sse = []
for i in range(1, 11):
    km = KMeans( n_clusters=i )
    km.fit(data_pca)
    sse.append(km.inertia_)
# plot
plt.plot(range(1, 11), sse, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('SSE')
plt.show()
score=[]
n=range(2,15)
for i in n:
      km = KMeans(n_clusters=i)
      km = km.fit(data_pca)
      cluster_labels=km.labels_
      score.append(silhouette_score(data_pca, cluster_labels))
k=score.index(max(score))
print("best n:" ,k)
print("best silhouette_score:",score[k-1])
plt.plot(score)
plt.xlabel('Values of n') 
plt.ylabel('Silhouette score') 
plt.title('Silhouette analysis For Optimal k')
plt.show()
kmeans = KMeans(n_clusters=3, random_state=0).fit(data_pca)
df_['cluster'] = kmeans.labels_
df_
df_n=df_.drop(['country'], axis =1)
Cluster 1
df_[df_['cluster'] == 0]
cluster 2
df_[df_['cluster'] == 1]
Cluster 3
df_[df_['cluster'] == 2]
fig,ax = plt.subplots(2,3, figsize=(15,7),squeeze=False)
sns.barplot(x='cluster', y=df_n.columns[0],data=df_n,ax=ax[0,0])
sns.barplot(x='cluster', y=df_n.columns[1],data=df_n,ax=ax[0,1])
sns.barplot(x='cluster', y=df_n.columns[2],data=df_n,ax=ax[0,2])
sns.barplot(x='cluster', y=df_n.columns[4],data=df_n,ax=ax[1,0])
sns.barplot(x='cluster', y=df_n.columns[6],data=df_n,ax=ax[1,1])
sns.barplot(x='cluster', y=df_n.columns[8],data=df_n,ax=ax[1,2])

plt.show()
The above barplot shows that Cluster that has been clsasified as 0 is the most under developed 
#Hierarchical clustering
df2=df.copy()
plt.figure(figsize=(50, 12))
dend=hcluster.dendrogram(hcluster.linkage(df_standard,method='ward'))
As we can see from the dendogram that the optimum number of cluster is 3 therefore applying **AgglomerativeClustering  **
hcluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  
hcluster.fit_predict(df_standard)
hcluster_label = hcluster.labels_
hcluster_df = pd.DataFrame(df2)
hcluster_df['hcluster'] = hcluster_label
hcluster_df['hcluster'].value_counts()
hcluster_df_n=hcluster_df.drop(['country'], axis =1)
hcluster_df_n
for i in range(9):
  for  j in range(i+1,9):
    sns.scatterplot(x=hcluster_df_n.iloc[:, i], y=hcluster_df_n.iloc[:, j], hue='hcluster', data=hcluster_df_n)
    plt.title(hcluster_df_n.columns[i]+" vs "+hcluster_df_n.columns[j], fontsize=15)
    plt.xlabel(hcluster_df_n.columns[i], fontsize=12)
    plt.ylabel(hcluster_df_n.columns[j], fontsize=12)
    plt.show()
fig,ax = plt.subplots(2,3, figsize=(20,10),squeeze=False)
sns.barplot(x='hcluster', y=hcluster_df_n.columns[0],data=hcluster_df_n,ax=ax[0,0])
sns.barplot(x='hcluster', y=hcluster_df_n.columns[1],data=hcluster_df_n,ax=ax[0,1]) 
sns.barplot(x='hcluster', y=hcluster_df_n.columns[2],data=hcluster_df_n,ax=ax[0,2]) 
sns.barplot(x='hcluster', y=hcluster_df_n.columns[4],data=hcluster_df_n,ax=ax[1,0]) 
sns.barplot(x='hcluster', y=hcluster_df_n.columns[6],data=hcluster_df_n,ax=ax[1,1]) 
sns.barplot(x='hcluster', y=hcluster_df_n.columns[8],data=hcluster_df_n,ax=ax[1,2]) 

plt.show()
Class 2 is in need of funds

Class 1 can need funds but are better than class 2

Class 0 are developed countries that may not need ant funds
under_developing_h=hcluster_df[hcluster_df_n['hcluster']==2]['country']
developing_h=hcluster_df[hcluster_df_n['hcluster']==1]['country']
developed_h=hcluster_df[hcluster_df_n['hcluster']==0]['country']
under_developing_h
developing_h
developed_h
hcluster_df_copy=hcluster_df.copy()
hcluster_df_copy['hcluster'].loc[hcluster_df_copy['hcluster'] == 0] = 'No Help Needed'
hcluster_df_copy['hcluster'].loc[hcluster_df_copy['hcluster'] == 1] = 'Might need help'
hcluster_df_copy['hcluster'].loc[hcluster_df_copy['hcluster'] == 2] = 'Need Help'
fig = px.choropleth(hcluster_df_copy[['country','hcluster']],
                    locationmode = 'country names',
                    locations = 'country',
                    title = 'Needed Help Per Country (World)',
                    color = hcluster_df_copy['hcluster'],  
                    color_discrete_map = {'Help Needed':'Red',
                                        'No Help Needed':'Green',
                                        'Might Need Help':'Yellow'}
                   )
fig.update_geos(fitbounds = "locations", visible = True)
fig.update_layout(legend_title_text = 'Labels',legend_title_side = 'top',title_pad_l = 260,title_y = 0.86)
fig.show(engine = 'kaleido')
# Hirerarchial on PCA dataset
df_1=df.copy()
plt.figure(figsize=(50, 12))
dend=hcluster.dendrogram(hcluster.linkage(data_pca,method='ward'))
The dendogram shows that number of optimal cluster is 3
hcluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  
hcluster.fit_predict(data_pca)
hcluster_label_pca= hcluster.labels_
hcluster_df_pca = pd.DataFrame(df_1)
hcluster_df_pca['hcluster'] = hcluster_label_pca
hcluster_df_pca_n=hcluster_df_pca.drop(['country'], axis =1)
fig,ax = plt.subplots(2,3, figsize=(15,7),squeeze=False)
sns.barplot(x='hcluster', y=hcluster_df_pca_n.columns[0],data=hcluster_df_pca_n,ax=ax[0,0])
sns.barplot(x='hcluster', y=hcluster_df_pca_n.columns[1],data=hcluster_df_pca_n,ax=ax[0,1])
sns.barplot(x='hcluster', y=hcluster_df_pca_n.columns[2],data=hcluster_df_pca_n,ax=ax[0,2])
sns.barplot(x='hcluster', y=hcluster_df_pca_n.columns[4],data=hcluster_df_pca_n,ax=ax[1,0])
sns.barplot(x='hcluster', y=hcluster_df_pca_n.columns[6],data=hcluster_df_pca_n,ax=ax[1,1])
sns.barplot(x='hcluster', y=hcluster_df_pca_n.columns[8],data=hcluster_df_pca_n,ax=ax[1,2])

plt.show()
We can see from the above bar plot that cluster containing class 1 is the cluster that needs the most help
hcluster_df_pca[hcluster_df_pca['hcluster'] == 0]
hcluster_df_pca[hcluster_df_pca['hcluster'] == 1]
hcluster_df_pca[hcluster_df_pca['hcluster'] == 2]
CLASS 0- DEVELOPED

CLASS-1 UNDER DEVELOPED

CLASS 2 DEVELOPING
hcluster_df_pca['hcluster'].loc[hcluster_df_pca['hcluster'] == 1] = 'Help Needed'
hcluster_df_pca['hcluster'].loc[hcluster_df_pca['hcluster'] == 2] = 'Might need help'
hcluster_df_pca['hcluster'].loc[hcluster_df_pca['hcluster'] == 0] = 'No need'
fig = px.choropleth(hcluster_df_pca[['country','hcluster']],
                    locationmode = 'country names',
                    locations = 'country',
                    title = 'Needed Help Per Country (World)',
                    color = hcluster_df_pca['hcluster'],  
                    color_discrete_map = {'Help Needed':'Red',
                                        'No Help Needed':'Green',
                                        'Might Need Help':'Yellow'}
                   )
fig.update_geos(fitbounds = "locations", visible = True)
fig.update_layout(legend_title_text = 'Labels',legend_title_side = 'top',title_pad_l = 260,title_y = 0.86)
fig.show(engine = 'kaleido')
# DBSCAN
df3=df.copy()
neighbors = NearestNeighbors(n_neighbors=20)
neighbors_fit = neighbors.fit(df_standard)
distances, indices = neighbors_fit.kneighbors(df_standard)

distances = np.sort(distances, axis=0)
distances = distances[:,1]
plt.plot(distances)
dbscan = DBSCAN(eps=1.3, min_samples=15)
labels = dbscan.fit_predict(df_standard)
dbs_df = pd.DataFrame(df3)
dbs_df['dbcluster'] = labels
dbs_df
dbs_df['dbcluster'].nunique()
dbs_df_n=dbs_df.drop(['country'], axis =1)
fig,ax = plt.subplots(2,3, figsize=(20,10),squeeze=False)
sns.barplot(x='dbcluster', y=dbs_df_n.columns[0],data=dbs_df_n,ax=ax[0,0])
sns.barplot(x='dbcluster', y=dbs_df_n.columns[1],data=dbs_df_n,ax=ax[0,1]) 
sns.barplot(x='dbcluster', y=dbs_df_n.columns[2],data=dbs_df_n,ax=ax[0,2]) 
sns.barplot(x='dbcluster', y=dbs_df_n.columns[4],data=dbs_df_n,ax=ax[1,0]) 
sns.barplot(x='dbcluster', y=dbs_df_n.columns[6],data=dbs_df_n,ax=ax[1,1]) 
sns.barplot(x='dbcluster', y=dbs_df_n.columns[8],data=dbs_df_n,ax=ax[1,2]) 
plt.show()
under_developed=dbs_df[dbs_df['dbcluster']==-1]['country']
developing=dbs_df[dbs_df['dbcluster']==0]['country']
developed=dbs_df[dbs_df['dbcluster']==1]['country']
under_developed
developing
developed
dbs_df_copy=dbs_df.copy()
dbs_df_copy['dbcluster'].loc[dbs_df_copy['dbcluster'] == -1] = 'Help Needed'
dbs_df_copy['dbcluster'].loc[dbs_df_copy['dbcluster'] == 0] = 'Might need help'
dbs_df_copy['dbcluster'].loc[dbs_df_copy['dbcluster'] == 1] = 'No need of Help'
fig = px.choropleth(dbs_df_copy[['country','dbcluster']],
                    locationmode = 'country names',
                    locations = 'country',
                    title = 'Needed Help Per Country (World)',
                    color = dbs_df_copy['dbcluster'],  
                    color_discrete_map = {'Help Needed':'Red',
                                        'No Help Needed':'Green',
                                        'Might Need Help':'Yellow'}
                   )
fig.update_geos(fitbounds = "locations", visible = True)
fig.update_layout(legend_title_text = 'Labels',legend_title_side = 'top',title_pad_l = 260,title_y = 0.86)
fig.show(engine = 'kaleido')
